{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjfodDEmCWXqjIOr9G4738",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nssn96/ML_iris/blob/main/ML_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Assignmet 1 - Iris dataset"
      ],
      "metadata": {
        "id": "Mcgpr46pdcs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import statements\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xWpiGmA3ePEr"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the iris dataset\n",
        "iris_dataset=load_iris()\n",
        "print(type(iris_dataset))"
      ],
      "metadata": {
        "id": "Ov6VyxCgdjHR",
        "outputId": "9b657eec-4e26-4f3e-eead-bac3cf66f283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to explore the iris_dataset dictionary and understand the different available keys and thier values\n",
        "print(iris_dataset.keys())\n",
        "#print(iris_dataset.data)\n",
        "print(iris_dataset.target)\n",
        "print(iris_dataset.frame)\n",
        "print(iris_dataset.target_names)\n",
        "print(iris_dataset.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1usr410yxycz",
        "outputId": "c84c43f8-dfe0-42b1-f16a-1dcf8c1e775e"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "None\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above code snippet we can see that we have \n",
        "\n",
        "*   Four input features, which are sepal length, sepal width, petal length, petal width.\n",
        "*   Three target names depending on the input features. The target names are : setosa=0, versicolor=1,virginica=2\n",
        "\n"
      ],
      "metadata": {
        "id": "V2doMOOCyqzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#storing features and target of iris dataset separately\n",
        "x = pd.DataFrame(iris_dataset.data)  # x is in matrix format\n",
        "y=pd.DataFrame(iris_dataset.target)   # y is in a vector format\n",
        "x.columns=['sepal_length','sepal_width','petal_length','petal_width']\n",
        "y.columns=['target']"
      ],
      "metadata": {
        "id": "MZNkZVqGwgmk"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to check the number/size of the data matrix\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkMW3sLK_VSr",
        "outputId": "196d0aa4-6c0e-4f11-adad-34a2620fc1d9"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, from above code we can see that we have a total of 150 samples of input features"
      ],
      "metadata": {
        "id": "G4ZizbR5JERI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting to dataframe\n",
        "data = pd.DataFrame(data= np.c_[iris_dataset['data'], iris_dataset['target']],columns= iris_dataset['feature_names'] + ['target'])\n",
        "data['species'] = pd.Categorical.from_codes(iris_dataset.target,iris_dataset.target_names)\n",
        "data.columns=['sepal_length','sepal_width','petal_length','petal_width','target','species']"
      ],
      "metadata": {
        "id": "0cSwA56xKnC-"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plt.scatter(data.sepal_length,data.sepal_width)\n",
        "# plt.xlabel(\"Sepal length\")\n",
        "# plt.ylabel(\"Sepal Width\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "poKw02LJiiLa"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data into train and test set\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1, random_state=1,stratify = y)"
      ],
      "metadata": {
        "id": "2l3jcUKRtx6W"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x1=x_train.petal_length\n",
        "# y1 = x_train.petal_width\n",
        "# num_obs = len(x1)\n",
        "# noise = np.random.normal(loc=0.0, scale=5.0, size=num_obs)\n",
        "# y= 10+(2*x1)+noise\n",
        "\n",
        "# plt.figure(figsize=(20,7))\n",
        "# plt.plot(x1, y, 'o')\n"
      ],
      "metadata": {
        "id": "UYSzxwiU-ZW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class definition for Linear regression\n",
        "class LinearRegression:\n",
        "\n",
        "  def fit(self,data,target,steps=100):\n",
        "    alpha=0.01 #learning rate\n",
        "    self.m = data.shape #num of training examples,features\n",
        "    self.data=data\n",
        "    self.target=target\n",
        "    self.bias=0\n",
        "    self.w=np.zeros(self.m)\n",
        "    loss_arr=[]\n",
        "\n",
        "    for i in range(steps):\n",
        "      target_pred = self.predict(self.data)\n",
        "\n",
        "\n",
        "      # calculate gradient descent\n",
        "      dbias = -2 * np.sum(self.target-target_pred) / self.m\n",
        "      dw = -(2 * (self.data.T).dot(self.target-target_pred)) / self.m\n",
        "\n",
        "      #least square function\n",
        "      #mse_loss =  (np.sum((self.target-target_pred) ** 2)) / self.m\n",
        "      #mse_loss = np.square(np.subtract(self.target,target_pred)).mean()\n",
        "      mse_loss = mean_squared_error(self.target,target_pred)\n",
        "      loss_arr.append(mse_loss)\n",
        "\n",
        "      #update weights\n",
        "      self.bias-= (alpha * dbias)\n",
        "      self.w -= (alpha * dw)\n",
        "\n",
        "    return loss_arr\n",
        "\n",
        "  def predict(self,data):\n",
        "    return data.dot(self.w) + self.bias\n"
      ],
      "metadata": {
        "id": "Mp8G8tMhqqzY"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 12 diff combinations of models\n",
        "# model = LinearRegression()\n",
        "# print(len(x1))\n",
        "# l  = model.fit(x1,y1)\n",
        "# print(l)\n",
        "# # step_num = range(1,101)\n",
        "# # plt.plot(step_num, l, label='loss vs step')"
      ],
      "metadata": {
        "id": "qRKYQ82Rcxir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 diff combinations of models\n",
        "model = LinearRegression()\n",
        "temp = ['sepal_length','sepal_width','petal_length','petal_width']\n",
        "li = list(itertools.permutations(temp,2))\n",
        "\n",
        "for i in li:\n",
        "  feature1=i[0]\n",
        "  feature2=i[1]\n",
        "  x1 = x_train[feature1]\n",
        "  y1 = x_train[feature2]\n",
        "  l  = model.fit(x1,y1)\n",
        "  print(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IFiSJolQOES2",
        "outputId": "53eb7064-ca22-40ea-b87c-297b6d4f1f72"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-5297fa4a50c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0ml\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-200-142320cf43ee>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, target, steps)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#mse_loss =  (np.sum((self.target-target_pred) ** 2)) / self.m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m#mse_loss = np.square(np.subtract(self.target,target_pred)).mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mloss_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \"\"\"\n\u001b[1;32m    438\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise TypeError(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array 0.0 cannot be considered a valid collection."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # fitting the model with data set\n",
        "\n",
        "# # reg_sgd = SGDRegressor(loss='squared_error', max_iter=100)\n",
        "# # reg_sgd.fit(X,y)\n",
        "# # y_hat_pred = reg_sgd.predict(X_test)\n",
        "# backup = data\n",
        "\n",
        "\n",
        "\n",
        "# MSE_score_train = []\n",
        "# MSE_score_test = []\n",
        "\n",
        "# mod_no = range(1,13)\n",
        "# for i in mod_no:\n",
        "#   model = SGDRegressor(loss=\"squared_error\", max_iter=100)\n",
        "#   model.fit(x_train, y_train)\n",
        "#   y_train_hat  = model.predict(x_train)\n",
        "#   y_test_hat  = model.predict(x_test)\n",
        "#   MSE_score_train.append(-1 * mean_squared_error(y_train,y_train_hat))\n",
        "#   MSE_score_test.append(-1 * mean_squared_error(y_test,y_test_hat))\n",
        "    \n",
        "# plt.plot(mod_no,  MSE_score_train, label='train')\n",
        "# plt.plot(mod_no,  MSE_score_test, label='test')\n",
        "# plt.xlabel(\"Model Number\")\n",
        "# plt.ylabel(\"MSE\")\n",
        "# plt.legend()\n",
        "\n",
        "# # plt.annotate('Sweet Spot', xy = (9, -.005), xytext=(9, -.015),\n",
        "# #             arrowprops = dict(facecolor='black', shrink = 0.05));"
      ],
      "metadata": {
        "id": "DShBg5BQay70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}